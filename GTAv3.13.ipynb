{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3c86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import webbrowser\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from PIL import Image\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636799e3",
   "metadata": {},
   "source": [
    "# Global Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604c56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "random_min=50.45\n",
    "random_max=86.79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195f000",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8b465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location             : US\n",
      "Start Date           : 2023-09-15\n",
      "End Date             : 2018-09-15\n",
      "Previous Year Date   : 2022-09-15\n",
      "Keywords>>\n",
      "['American padlock', 'Assa Abloy padlock', 'Medeco padlock', 'Squire padlock', 'Abloy padlock', 'ABUS padlock', 'Yale padlock', 'Schlage padlock', 'Kwikset padlock']\n"
     ]
    }
   ],
   "source": [
    "#Storing data from file Panda DF\n",
    "input_keywords_df = pd.read_excel('Keywords_List.xlsx')\n",
    "\n",
    "#Storing keywords to a list\n",
    "input_keyword_list = input_keywords_df[\"Keywords\"].values.tolist()\n",
    "#Removing any repeating keywords\n",
    "input_keyword_list = list(set(input_keyword_list))\n",
    "\n",
    "# Storing Location and Timeframe data\n",
    "geo_input = input_keywords_df[\"Location\"].values.tolist()\n",
    "geo_input=geo_input[0]\n",
    "timeframe_input = input_keywords_df[\"Timeframe\"].values.tolist()\n",
    "timeframe_input=timeframe_input[0]\n",
    "\n",
    "\n",
    "####################################################################\n",
    "print(\"Location             :\",geo_input)\n",
    "\n",
    "#Time Frmae Data\n",
    "timeframe_list=timeframe_input.split()\n",
    "end_date=timeframe_list[0]\n",
    "start_date=timeframe_list[1]\n",
    "print(\"Start Date           :\",start_date)\n",
    "print(\"End Date             :\",end_date)\n",
    "\n",
    "# Convert the start date string to a datetime.date object\n",
    "start_date_2 = datetime.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "# Calculate the date one year before the start date\n",
    "previous_year_date = start_date_2 - relativedelta(years=1)\n",
    "print(\"Previous Year Date   :\",previous_year_date)\n",
    "\n",
    "print(\"Keywords>>\")\n",
    "print(input_keyword_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdaed57",
   "metadata": {},
   "source": [
    "# Reference Keyword | Among 5 Random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd79e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep_start 68.51260202232588\n",
      "sleep_middle 67.40378655650323\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "#Choosing a good candidate keyword to keep as reference for rest of the keywords by running a trial Google Trends\n",
    "#Taking out first 5 keywords as sample\n",
    "trial_keywords=input_keyword_list[:5]\n",
    "\n",
    "#Trial Pytrends - Google Trends connection request for trial keywords\n",
    "trial_pytrends_request=TrendReq()\n",
    "\n",
    "# Generate a random delay between, for example, 10 and 20 seconds\n",
    "delay_seconds = random.uniform(random_min, random_max)\n",
    "print(\"sleep_start\",delay_seconds)\n",
    "time.sleep(delay_seconds)  \n",
    "\n",
    "#Google Trends data loaded based on Location and Timeframe for trial keywords\n",
    "trial_pytrends_request.build_payload(trial_keywords,geo=geo_input,timeframe=timeframe_input)\n",
    "\n",
    "# Generate a random delay between, for example, 10 and 20 seconds\n",
    "delay_seconds = random.uniform(random_min, random_max)\n",
    "print(\"sleep_middle\",delay_seconds)\n",
    "time.sleep(delay_seconds)  \n",
    "\n",
    "#Interest over time is stored for trial keywords - output is Pandas data frames\n",
    "trial_pytrends_df=trial_pytrends_request.interest_over_time()\n",
    "\n",
    "#Dropping \"isPartial\" column from the pytrends dataframe\n",
    "trial_pytrends_df.drop(columns=[\"isPartial\"], inplace=True)\n",
    "\n",
    "# Average values of each keywords and keywords list\n",
    "trial_average=trial_pytrends_df.mean().tolist()\n",
    "trial_keywords=trial_pytrends_df.columns.tolist()\n",
    "\n",
    "#Sorting/Ranking the keywords\n",
    "np_trial_average=np.array(trial_average)\n",
    "np_trial_keywords=np.array(trial_keywords)\n",
    "\n",
    "np_trial_average_sorted_index=np.argsort(np_trial_average)\n",
    "trial_average_sorted=np_trial_average[np_trial_average_sorted_index].tolist()\n",
    "trial_keywords_sorted=np_trial_keywords[np_trial_average_sorted_index].tolist()\n",
    "\n",
    "#Storing First Keyword\n",
    "#hich will be used as linking keyword across all sets and will be used to normalise with resprct to each other later\n",
    "first_keyword=trial_keywords_sorted[-1]\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8c134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Assa Abloy padlock', 'Medeco padlock', 'Squire padlock', 'Abloy padlock', 'American padlock']\n",
      "[0.0, 5.919540229885057, 6.363984674329502, 10.544061302681992, 17.35249042145594]\n",
      "First/Reference Keywrd: American padlock\n"
     ]
    }
   ],
   "source": [
    "print(trial_keywords_sorted)\n",
    "print(trial_average_sorted)\n",
    "print(\"First/Reference Keywrd:\",first_keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5f198",
   "metadata": {},
   "source": [
    "#Harcoding First Keyword\n",
    "#first_keyword=\"Keyed alike padlock\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a45d3",
   "metadata": {},
   "source": [
    "# 4 Set and 5 Set Keyword Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53533d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing first keyword from main set and storing rest of the keyword\n",
    "rest_of_keywords=input_keyword_list[:]\n",
    "rest_of_keywords.pop(rest_of_keywords.index(first_keyword))\n",
    "\n",
    "#List to store sets/lists of 5 keywords\n",
    "keyword_sets=[]\n",
    "\n",
    "#Making sets/lists of 4 keywords from rest all keywords\n",
    "for i in range(0,len(rest_of_keywords),4):\n",
    "    keyword_sets.append(rest_of_keywords[i:i+4])\n",
    "#Now inserts first/reference keyword in all the above sets/lists which has only 4 keywords\n",
    "for i in range(0,len(keyword_sets)):\n",
    "    keyword_sets[i].insert(0,first_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c3ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Total Sets of Keywords with \"American padlock\" as the Reference Keyword\n",
      "[['American padlock', 'Assa Abloy padlock', 'Medeco padlock', 'Squire padlock', 'Abloy padlock'], ['American padlock', 'ABUS padlock', 'Yale padlock', 'Schlage padlock', 'Kwikset padlock']]\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(keyword_sets)} Total Sets of Keywords with \"{first_keyword}\" as the Reference Keyword')\n",
    "print(keyword_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796323e",
   "metadata": {},
   "source": [
    "# Pytrends API > Google Trends Conenction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2513294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep_start 0 67.5196560198105\n",
      "sleep_middle 0 83.8103983701472\n",
      "sleep_end 0 65.2586220482471\n",
      "sleep_start 1 59.29130481524049\n",
      "sleep_middle 1 80.77323194894583\n",
      "sleep_end 1 50.8276593579569\n",
      "Completed Google\n"
     ]
    }
   ],
   "source": [
    "#List created to store Google Trends Connection request for each set of 5 keywords\n",
    "pytrends_request_list=[]\n",
    "pytrends_df_list=[]\n",
    "\n",
    "for i in range(len(keyword_sets)):\n",
    "    #Google Trends Connection requests stored\n",
    "    pytrends_request_list.append(TrendReq())\n",
    "    \n",
    "    # Generate a random delay between, for example, 10 and 20 seconds\n",
    "    delay_seconds = random.uniform(random_min, random_max)\n",
    "    print(\"sleep_start\",i,delay_seconds)\n",
    "    time.sleep(delay_seconds)  \n",
    "    \n",
    "    #Keyword Data points are requested based on Location and Timeframe\n",
    "    pytrends_request_list[i].build_payload(keyword_sets[i],geo=geo_input,timeframe=timeframe_input)\n",
    "    \n",
    "    # Generate a random delay between, for example, 10 and 20 seconds\n",
    "    delay_seconds = random.uniform(random_min, random_max)\n",
    "    print(\"sleep_middle\",i,delay_seconds)\n",
    "    time.sleep(delay_seconds)\n",
    "    \n",
    "    #Interest over time is stored for each set/list - output is Pandas data frames, which is stored in a list for each set\n",
    "    pytrends_df_list.append(pytrends_request_list[i].interest_over_time())\n",
    "    \n",
    "    # Generate a random delay between, for example, 10 and 20 seconds\n",
    "    delay_seconds = random.uniform(random_min, random_max)\n",
    "    print(\"sleep_end\",i,delay_seconds)\n",
    "    time.sleep(delay_seconds)  \n",
    "    \n",
    "    #Dropping \"isPartial\" column from the pytrends dataframe\n",
    "    pytrends_df_list[i].drop(columns=[\"isPartial\"], inplace=True)\n",
    "    \n",
    "        \n",
    "gta_df_backup=pytrends_df_list.copy()\n",
    "print(\"Completed Google\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb0edb",
   "metadata": {},
   "source": [
    "#Refresh Dataframe\n",
    "#pytrends_df_list=gta_df_backup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c8954",
   "metadata": {},
   "source": [
    "# DATA WRANGLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a416e6",
   "metadata": {},
   "source": [
    "# Combining & Normalization of all DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aecfb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refresh Dataframe\n",
    "pytrends_df_list=gta_df_backup.copy()\n",
    "\n",
    "#### Try taking rank only for latt year | Clean the datframe index date and filter for last year\n",
    "\n",
    "# Max of the reference keyword is is exttracted from all dataframes\n",
    "maxReferenceKeyword=[]\n",
    "for i in range(len(pytrends_df_list)):\n",
    "    maxReferenceKeyword.append(pytrends_df_list[i][first_keyword].max())\n",
    "    \n",
    "#Normalization factor is obtained uaing reference keyword\n",
    "normalizationFactor=[]\n",
    "for i in range(len(pytrends_df_list)):\n",
    "    normalizationFactor.append(maxReferenceKeyword[0]/maxReferenceKeyword[i])\n",
    "\n",
    "#All the Dataframes are Normalized using Normalization Factor\n",
    "for i in range(len(pytrends_df_list)):\n",
    "    pytrends_df_list[i]=pytrends_df_list[i]*normalizationFactor[i]\n",
    "\n",
    "#Removing - the first elemnt data/column from Dataframe in the first set/list which was repeated in rest of the set/list\n",
    "for i in range(1,len(pytrends_df_list)):\n",
    "    pytrends_df_list[i].drop(columns=[first_keyword],inplace=True)\n",
    "\n",
    "#Combined Dataframe\n",
    "combined_df=pytrends_df_list[0]\n",
    "for i in range(1,len(pytrends_df_list)):\n",
    "    combined_df=combined_df.join(pytrends_df_list[i])\n",
    "\n",
    "#Extracting Max value from the dataframe, and use it to normalise the entire dataframe so that max is 100\n",
    "max_trend_datapoint=combined_df.to_numpy().max()\n",
    "\n",
    "# Normalising the combined dataframe to 100 scale\n",
    "normalise100_factor=(100-max_trend_datapoint)/max_trend_datapoint\n",
    "normalise100_factor=1+normalise100_factor\n",
    "normalised_df=combined_df*normalise100_factor\n",
    "normalised_df=normalised_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e36597",
   "metadata": {},
   "source": [
    "# Ranking the Keywords | Previous Year Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f31385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking to be been calculated based on previous year popularity\n",
    "normalised_df_1year=normalised_df[previous_year_date:start_date]\n",
    "\n",
    "# Mean/Average values of each keywords and keywords list\n",
    "average_list=normalised_df_1year.mean().tolist()\n",
    "keyword_list=normalised_df_1year.columns.tolist()\n",
    "\n",
    "#List to Numpy\n",
    "np_average_list=np.array(average_list)\n",
    "np_keyword_list=np.array(keyword_list)\n",
    "\n",
    "# Sorting/Ranking the average\n",
    "np_sorted_avg_index=np.argsort(np_average_list)\n",
    "\n",
    "np_sorted_average=np_average_list[np_sorted_avg_index][::-1]\n",
    "\n",
    "# Normalizing the average to 100\n",
    "normalise100factor_np=(100-np_sorted_average[0])/np_sorted_average[0]\n",
    "normalise100factor_np=1+normalise100factor_np\n",
    "normalised_avg_list_np=np.round_(np_sorted_average*normalise100factor_np,1)\n",
    "\n",
    "# Sorting/Ranking the keywords\n",
    "np_sorted_keywords=np_keyword_list[np_sorted_avg_index][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140fb457",
   "metadata": {},
   "source": [
    "# Sorting the Combined Multi-Year DataFrame based on last year performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b55446",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df=normalised_df[np_sorted_keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2edd7c5",
   "metadata": {},
   "source": [
    "print(normalised_avg_list_np)\n",
    "print(np_sorted_keywords)\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ed5ef",
   "metadata": {},
   "source": [
    "# URLs Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fdc4c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://trends.google.com/trends/explore?date=2018-09-15%202023-09-15&geo=US&q=ABUS padlock,American padlock,Yale padlock,Abloy padlock,Schlage padlock',\n",
       " 'https://trends.google.com/trends/explore?date=2018-09-15%202023-09-15&geo=US&q=Schlage padlock,Kwikset padlock,Squire padlock,Medeco padlock,Assa Abloy padlock']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_string_list = []\n",
    "joined_keywords = \"\"\n",
    "counter = 0\n",
    "\n",
    "for i in range(len(np_sorted_keywords)):\n",
    "    joined_keywords += \",\" + np_sorted_keywords[i]  # Join the current element with a comma\n",
    "    counter += 1\n",
    "\n",
    "    if counter == 5 or i == len(np_sorted_keywords) - 1:\n",
    "        keywords_string_list.append(joined_keywords[1:])  # Append the joined string, excluding the leading comma\n",
    "        counter = 0\n",
    "        joined_keywords = \"\"\n",
    "        \n",
    "        joined_keywords += \",\" + np_sorted_keywords[i]  # Join the current element with a comma\n",
    "        counter += 1\n",
    "\n",
    "urls=[]\n",
    "url_base_string=\"https://trends.google.com/trends/explore?date=\"+end_date+\"%20\"+start_date+\"&geo=\"+geo_input+\"&q=\"\n",
    "\n",
    "for i in keywords_string_list:\n",
    "    url=url_base_string+i\n",
    "    urls.append(url)\n",
    "\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c31fc",
   "metadata": {},
   "source": [
    "# Custom Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c97d4f5",
   "metadata": {},
   "source": [
    "#Top5List\n",
    "normalised_avg_list5_np=normalised_avg_list_np[:5]\n",
    "np_sorted_keywords5=np_sorted_keywords[:5]\n",
    "top_5df=normalised_df[np_sorted_keywords5]\n",
    "\n",
    "#Top10List\n",
    "normalised_avg_list10_np=normalised_avg_list_np[:10]\n",
    "np_sorted_keywords10=np_sorted_keywords[:10]\n",
    "top_10df=normalised_df[np_sorted_keywords10]\n",
    "\n",
    "#Top15List\n",
    "normalised_avg_list15_np=normalised_avg_list_np[:15]\n",
    "np_sorted_keywords15=np_sorted_keywords[:15]\n",
    "top_15df=normalised_df[np_sorted_keywords15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a447eee",
   "metadata": {},
   "source": [
    "# Plotting 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c083a",
   "metadata": {},
   "source": [
    "y_pos=np.arange(len(np_sorted_keywords15))\n",
    "plt.barh(y_pos,normalised_avg_list15_np[::-1],align='center',alpha=0.5)\n",
    "plt.yticks(y_pos,np_sorted_keywords15[::-1])\n",
    "plt.xlabel('Average ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c06733",
   "metadata": {},
   "source": [
    "# Excel Reporting/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90dc034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'Keyword_Ranking_2023-09-29_18-40-21.xlsx' saved in folder 'GTA_Ranking_2023-09-29_18-40-21'\n"
     ]
    }
   ],
   "source": [
    "#Creating Rank numbers to populate in Excel\n",
    "ranks=np.arange(1,len(np_sorted_keywords)+1)\n",
    "\n",
    "#Adding Keywords and their Averages\n",
    "ranking_np= np.array([ranks,np_sorted_keywords,normalised_avg_list_np])\n",
    "\n",
    "#Trasposing the NDArray\n",
    "ranking_np=ranking_np.transpose()\n",
    "\n",
    "#Numpy to Pandas\n",
    "ranking_df=pd.DataFrame(data=ranking_np, columns=[\"Rank\",\"Keywords\", \"Average-1Year\"])\n",
    "\n",
    "# Create a folder for Links with the timestamp\n",
    "folder_name = f'GTA_Ranking_{current_datetime}'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Define the Excel file names with the timestamp\n",
    "excel_file_name = f'Keyword_Ranking_{current_datetime}.xlsx'\n",
    "\n",
    "#Save the DataFrame to an Excel file in the folder\n",
    "excel_file_path = os.path.join(folder_name, excel_file_name)\n",
    "ranking_df.to_excel(excel_file_path,index=False)\n",
    "\n",
    "# Print a message to confirm the completion\n",
    "print(f\"Excel file '{excel_file_name}' saved in folder '{folder_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22045967",
   "metadata": {},
   "source": [
    "# Create a folder for Links with the timestamp\n",
    "folder_name = f'GTA_Datapoints_{current_datetime}'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Define the Excel file names with the timestamp\n",
    "excel_file_name = f'Trends_Datapoints_{current_datetime}.xlsx'\n",
    "\n",
    "#Save the DataFrame to an Excel file in the folder\n",
    "excel_file_path = os.path.join(folder_name, excel_file_name)\n",
    "sorted_df.to_excel(excel_file_path,index=True)\n",
    "\n",
    "# Print a message to confirm the completion\n",
    "print(f\"Excel file '{excel_file_name}' saved in folder '{folder_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb308d0",
   "metadata": {},
   "source": [
    "# Download URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03547df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'Trend_Links_2023-09-29_18-40-21.xlsx' saved in folder 'GTA_Links_2023-09-29_18-40-21'\n"
     ]
    }
   ],
   "source": [
    "# Create a folder for Links with the timestamp\n",
    "folder_name = f'GTA_Links_{current_datetime}'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Create a DataFrame with your URLs\n",
    "links_df = pd.DataFrame(urls)\n",
    "\n",
    "# Define the Excel file name with the timestamp\n",
    "excel_file_name = f'Trend_Links_{current_datetime}.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file in the folder\n",
    "excel_file_path = os.path.join(folder_name, excel_file_name)\n",
    "links_df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Print a message to confirm the completion\n",
    "print(f\"Excel file '{excel_file_name}' saved in folder '{folder_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39cd89",
   "metadata": {},
   "source": [
    "# Auto Link Open in Browser Feature\n",
    "Works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb5cd7",
   "metadata": {},
   "source": [
    "# Set the time delay (in seconds) between opening links\n",
    "time_delay = 2  # Adjust this value as needed\n",
    "for url in urls:\n",
    "    webbrowser.open(url)\n",
    "    time.sleep(time_delay)\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd4c19",
   "metadata": {},
   "source": [
    "# Screen Shot Feature\n",
    "Works, but Not accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875ff8f",
   "metadata": {},
   "source": [
    "# Create a folder with a timestamp to store the screenshots\n",
    "screenshot_folder = f'GTA_Screenshots_{current_datetime}'\n",
    "os.makedirs(screenshot_folder, exist_ok=True)\n",
    "\n",
    "# Initialize the Edge browser driver with headless mode\n",
    "edge_options = webdriver.EdgeOptions()\n",
    "edge_options.add_argument('--headless')  # Enable headless mode\n",
    "driver = webdriver.Edge(options=edge_options)\n",
    "\n",
    "# Initialize a counter for image names\n",
    "image_counter = 1\n",
    "\n",
    "# Set the time delay (in seconds) between capturing screenshots\n",
    "time_delay = 5  # Adjust this value as needed\n",
    "time.sleep(time_delay)\n",
    "\n",
    "for url, keyword_string in zip(urls, keywords_string_list):\n",
    "    # Navigate to the web page\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load (you can adjust the sleep time as needed)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Capture a full-page screenshot of the web page\n",
    "    screenshot_filename = os.path.join(screenshot_folder, f'{image_counter:03d}_{keyword_string}.png')\n",
    "    driver.save_screenshot(screenshot_filename)\n",
    "\n",
    "    # Open the screenshot using Pillow (PIL)\n",
    "    img = Image.open(screenshot_filename)\n",
    "    \n",
    "    ## Define the cropping coordinates (left, top, right, bottom)\n",
    "    ## Adjust these values to crop the image as desired\n",
    "    #left = 50\n",
    "    #top = 80\n",
    "    #right = 900\n",
    "    #bottom = 900\n",
    "\n",
    "    ## Crop the image\n",
    "    #img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # Save the full-page screenshot\n",
    "    img.save(screenshot_filename)\n",
    "\n",
    "    # Increment the image counter\n",
    "    image_counter += 1\n",
    "    \n",
    "    # Add a time delay before capturing the next screenshot\n",
    "    time.sleep(time_delay)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "print(\"Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
